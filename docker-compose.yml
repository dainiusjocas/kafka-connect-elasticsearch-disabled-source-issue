version: '3'

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.6.2
    ports: ["9200:9200"]
    environment:
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - xpack.security.enabled=false

  kibana:
    image: docker.elastic.co/kibana/kibana:7.6.2
    ports: ["5601:5601"]
    environment:
      - xpack.security.enabled=false
      - ELASTICSEARCH_URL=http://elasticsearch:9200

  zookeeper:
    image: wurstmeister/zookeeper:3.4.6
    ports: ["2181:2181"]

  broker:
    image: wurstmeister/kafka:2.11-1.1.1
    ports: ["9092:9092"]
    depends_on:
      - zookeeper
    environment:
      KAFKA_ADVERTISED_HOST_NAME: localhost
      KAFKA_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_CREATE_TOPICS: ""
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

  restproxy:
    image: confluentinc/cp-kafka-rest:5.5.0
    ports: ["8082:8082"]
    depends_on:
      - zookeeper
      - broker
    environment:
      KAFKA_REST_HOST_NAME: restproxy
      KAFKA_REST_BOOTSTRAP_SERVERS: 'broker:29092'
      KAFKA_REST_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_REST_LOG4J_ROOT_LOGLEVEL: 'WARN'

  connect:
    build:
      context: .
      dockerfile: Dockerfile
    ports: ["8088:8088"]
    depends_on:
      - broker
    environment:
      CONNECT_BOOTSTRAP_SERVERS: broker:29092
      CONNECT_GROUP_ID: "connect-group"
      CONNECT_CONFIG_STORAGE_TOPIC: "connect-config-storage"
      CONNECT_OFFSET_STORAGE_TOPIC: "connect-offset-storage"
      CONNECT_STATUS_STORAGE_TOPIC: "connect-status-storage"
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
      CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.converters.ByteArrayConverter"
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_PLUGIN_PATH: "/usr/share/confluent-hub-components"
      CONNECT_REST_ADVERTISED_HOST_NAME: "connect"
      CONNECT_REST_HOST_NAME: "connect"
      CONNECT_REST_PORT: "8088"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-5.5.0.jar
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"

  control-center:
    image: confluentinc/cp-enterprise-control-center:5.5.0
    ports: ["9091:9091"]
    hostname: control-center
    depends_on:
      - zookeeper
      - broker
      - connect
    ports:
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'broker:29092'
      CONTROL_CENTER_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      CONTROL_CENTER_CONNECT_CLUSTER: 'connect:8088'
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONTROL_CENTER_LOG4J_ROOT_LOGLEVEL: 'WARN'
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1
      PORT: 9021
